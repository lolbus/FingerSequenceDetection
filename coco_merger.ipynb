{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205b69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# List of folders\n",
    "folders = ['01', '02']\n",
    "common_directory = '03'\n",
    "\n",
    "# Create the common directory if it doesn't exist\n",
    "if not os.path.exists(common_directory):\n",
    "    os.makedirs(common_directory)\n",
    "\n",
    "# Dictionary to hold name occurrences\n",
    "name_occurrences = defaultdict(int)\n",
    "\n",
    "# Move images to common directory and rename if necessary\n",
    "for folder in folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith('.png'):\n",
    "            name_occurrences[file_name] += 1\n",
    "            suffix = ''\n",
    "            if name_occurrences[file_name] > 1:\n",
    "                suffix = '_' + chr(96 + name_occurrences[file_name])\n",
    "                new_file_name = file_name[:-4] + suffix + '.png'\n",
    "            else:\n",
    "                new_file_name = file_name\n",
    "            os.rename(os.path.join(folder, file_name), os.path.join(common_directory, new_file_name))\n",
    "\n",
    "# Initialize merged coco data\n",
    "merged_coco_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [{\"id\": 1, \"name\": \"lefthand\"}, {\"id\": 2, \"name\": \"righthand\"}]\n",
    "}\n",
    "\n",
    "# Merge json files\n",
    "last_image_id = 0\n",
    "last_annotation_id = 0\n",
    "for folder in folders:\n",
    "    json_file = [f for f in os.listdir(folder) if f.endswith('.json')][0]\n",
    "    with open(os.path.join(folder, json_file)) as file:\n",
    "        coco_data = json.load(file)\n",
    "\n",
    "        # Update image ids and filenames\n",
    "        for image in coco_data['images']:\n",
    "            last_image_id += 1\n",
    "            image['id'] = last_image_id\n",
    "            occurrences = name_occurrences[image['file_name']]\n",
    "            if occurrences > 1:\n",
    "                suffix = '_' + chr(96 + occurrences)\n",
    "                image['file_name'] = image['file_name'][:-4] + suffix + '.png'\n",
    "            merged_coco_data['images'].append(image)\n",
    "\n",
    "        # Update annotation ids and round segmentation values\n",
    "        for annotation in coco_data['annotations']:\n",
    "            last_annotation_id += 1\n",
    "            annotation['id'] = last_annotation_id\n",
    "            annotation['image_id'] += last_image_id - len(coco_data['images'])\n",
    "            annotation['segmentation'] = [[round(value * 2) / 2 for value in seg] for seg in annotation['segmentation']]\n",
    "            merged_coco_data['annotations'].append(annotation)\n",
    "\n",
    "# Write merged json to file\n",
    "with open('merged_coco.json', 'w') as file:\n",
    "    json.dump(merged_coco_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92c909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Step 1: Copy and Rename Images\n",
    "common_directory = '03'\n",
    "os.makedirs(common_directory, exist_ok=True)\n",
    "\n",
    "folders = ['01', '02']\n",
    "\n",
    "for folder in folders:\n",
    "    images_path = os.path.join(folder, '*.png')\n",
    "    images = glob.glob(images_path)\n",
    "    for image_path in images:\n",
    "        basename = os.path.basename(image_path)\n",
    "        new_path = os.path.join(common_directory, basename)\n",
    "        \n",
    "        # Rename if file with the same name exists\n",
    "        suffix = ord('a') - 1\n",
    "        while os.path.exists(new_path):\n",
    "            suffix += 1\n",
    "            new_name = os.path.splitext(basename)[0] + \"_\" + chr(suffix) + \".png\"\n",
    "            new_path = os.path.join(common_directory, new_name)\n",
    "        \n",
    "        shutil.copy(image_path, new_path)\n",
    "\n",
    "# Step 2: Merge JSON files\n",
    "merged_data = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': []\n",
    "}\n",
    "\n",
    "image_id_offset = 0\n",
    "annotation_id_offset = 0\n",
    "\n",
    "for folder in folders:\n",
    "    json_file = [f for f in os.listdir(folder) if f.endswith('.json')][0]\n",
    "    with open(os.path.join(folder, json_file)) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        # Update image file_name and ids\n",
    "        for image in data['images']:\n",
    "            basename = image['file_name']\n",
    "            suffix = ord('a') - 1\n",
    "            while os.path.exists(os.path.join(common_directory, basename)):\n",
    "                suffix += 1\n",
    "                basename = os.path.splitext(image['file_name'])[0] + \"_\" + chr(suffix) + \".png\"\n",
    "\n",
    "            image['file_name'] = basename\n",
    "            image['id'] += image_id_offset\n",
    "            merged_data['images'].append(image)\n",
    "        \n",
    "        # Update annotations ids and round segmentation values\n",
    "        for annotation in data['annotations']:\n",
    "            annotation['id'] += annotation_id_offset\n",
    "            annotation['image_id'] += image_id_offset\n",
    "            annotation['segmentation'] = [[round(x * 2) / 2 for x in seg] for seg in annotation['segmentation']]\n",
    "            merged_data['annotations'].append(annotation)\n",
    "\n",
    "        image_id_offset = max(image['id'] for image in data['images']) + 1\n",
    "        annotation_id_offset = max(annotation['id'] for annotation in data['annotations']) + 1\n",
    "        \n",
    "    # Copy categories (assuming they are the same across folders)\n",
    "    if not merged_data['categories']:\n",
    "        merged_data['categories'] = data['categories']\n",
    "\n",
    "# Write merged data to file\n",
    "with open('merged_annotations.json', 'w') as file:\n",
    "    json.dump(merged_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71bc2f95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening.. 21Aug23_DDA\n",
      "0 processing for 21613.png\n",
      "1 processing for 21773.png\n",
      "2 processing for 21823.png\n",
      "3 processing for 21967.png\n",
      "4 processing for 22006.png\n",
      "5 processing for 22008.png\n",
      "6 processing for 22151.png\n",
      "7 processing for 22193.png\n",
      "8 processing for 22368.png\n",
      "9 processing for 22394.png\n",
      "10 processing for 22464.png\n",
      "11 processing for 22488.png\n",
      "12 processing for 22515.png\n",
      "13 processing for 22536.png\n",
      "14 processing for 22547.png\n",
      "15 processing for 22660.png\n",
      "16 processing for 22966.png\n",
      "17 processing for 23029.png\n",
      "18 processing for 23052.png\n",
      "19 processing for 23097.png\n",
      "20 processing for 23121.png\n",
      "21 processing for 23195.png\n",
      "22 processing for 23197.png\n",
      "23 processing for 23216.png\n",
      "24 processing for 23256.png\n",
      "25 processing for 23270.png\n",
      "26 processing for 23284.png\n",
      "27 processing for 23298.png\n",
      "28 processing for 23342.png\n",
      "29 processing for 23435.png\n",
      "30 processing for 23468.png\n",
      "31 processing for 23626.png\n",
      "32 processing for 23655.png\n",
      "33 processing for 23739.png\n",
      "34 processing for 23763.png\n",
      "35 processing for 23785.png\n",
      "opening.. 21Aug23_DDA_B\n",
      "0 processing for 24785.png\n",
      "1 processing for 24787.png\n",
      "2 processing for 24832.png\n",
      "3 processing for 25312.png\n",
      "4 processing for 25313.png\n",
      "5 processing for 25332.png\n",
      "6 processing for 25356.png\n",
      "7 processing for 25380.png\n",
      "8 processing for 25407.png\n",
      "9 processing for 25445.png\n",
      "10 processing for 25476.png\n",
      "11 processing for 25498.png\n",
      "12 processing for 25689.png\n",
      "13 processing for 25762.png\n",
      "14 processing for 25955.png\n",
      "15 processing for 26007.png\n",
      "opening.. 22Aug23_DDA\n",
      "0 processing for 28097.png\n",
      "1 processing for 28210.png\n",
      "2 processing for 28211.png\n",
      "3 processing for 28259.png\n",
      "4 processing for 28326.png\n",
      "5 processing for 28439.png\n",
      "6 processing for 28464.png\n",
      "7 processing for 28615.png\n",
      "8 processing for 28640.png\n",
      "9 processing for 28641.png\n",
      "10 processing for 28684.png\n",
      "11 processing for 28757.png\n",
      "12 processing for 28819.png\n",
      "13 processing for 28829.png\n",
      "14 processing for 28844.png\n",
      "15 processing for 28873.png\n",
      "16 processing for 28908.png\n",
      "17 processing for 28909.png\n",
      "18 processing for 28930.png\n",
      "19 processing for 28959.png\n",
      "20 processing for 29042.png\n",
      "21 processing for 29058.png\n",
      "22 processing for 29193.png\n",
      "23 processing for 29210.png\n",
      "24 processing for 29229.png\n",
      "25 processing for 29240.png\n",
      "26 processing for 29561.png\n",
      "27 processing for 29815.png\n",
      "28 processing for 29821.png\n",
      "29 processing for 30165.png\n",
      "30 processing for 30223.png\n",
      "31 processing for 30380.png\n",
      "32 processing for 30407.png\n",
      "33 processing for 30416.png\n",
      "34 processing for 30458.png\n",
      "35 processing for 30989.png\n",
      "36 processing for 31095.png\n",
      "opening.. 22Aug23_DDA_b\n",
      "0 processing for 32173.png\n",
      "1 processing for 32324.png\n",
      "2 processing for 32455.png\n",
      "3 processing for 32562.png\n",
      "4 processing for 32603.png\n",
      "5 processing for 32676.png\n",
      "6 processing for 33171.png\n",
      "7 processing for 33203.png\n",
      "8 processing for 33268.png\n",
      "9 processing for 34019.png\n",
      "10 processing for 34095.png\n",
      "11 processing for 35148.png\n",
      "12 processing for 35149.png\n",
      "13 processing for 35385.png\n",
      "14 processing for 36240.png\n",
      "15 processing for 36333.png\n",
      "16 processing for 36558.png\n",
      "17 processing for 36559.png\n",
      "18 processing for 36785.png\n",
      "19 processing for 38047.png\n",
      "20 processing for 38235.png\n",
      "21 processing for 38324.png\n",
      "22 processing for 38352.png\n",
      "23 processing for 38711.png\n",
      "24 processing for 38819.png\n",
      "25 processing for 39042.png\n",
      "26 processing for 39126.png\n",
      "27 processing for 39204.png\n",
      "opening.. 22Aug23_DDA_b\n",
      "0 processing for 32173.png\n",
      "1 processing for 32324.png\n",
      "2 processing for 32455.png\n",
      "3 processing for 32562.png\n",
      "4 processing for 32603.png\n",
      "5 processing for 32676.png\n",
      "6 processing for 33171.png\n",
      "7 processing for 33203.png\n",
      "8 processing for 33268.png\n",
      "9 processing for 34019.png\n",
      "10 processing for 34095.png\n",
      "11 processing for 35148.png\n",
      "12 processing for 35149.png\n",
      "13 processing for 35385.png\n",
      "14 processing for 36240.png\n",
      "15 processing for 36333.png\n",
      "16 processing for 36558.png\n",
      "17 processing for 36559.png\n",
      "18 processing for 36785.png\n",
      "19 processing for 38047.png\n",
      "20 processing for 38235.png\n",
      "21 processing for 38324.png\n",
      "22 processing for 38352.png\n",
      "23 processing for 38711.png\n",
      "24 processing for 38819.png\n",
      "25 processing for 39042.png\n",
      "26 processing for 39126.png\n",
      "27 processing for 39204.png\n"
     ]
    }
   ],
   "source": [
    "# Best Version Method 3\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "\n",
    "def round_to_nearest_half(number):\n",
    "    return round(number * 2) / 2\n",
    "\n",
    "def merge_datasets(folders, common_directory, t):\n",
    "    os.makedirs(common_directory, exist_ok=True)\n",
    "    image_id_offset = 0\n",
    "    annotation_id_offset = 0\n",
    "\n",
    "    final_json = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [{\"id\": 1, \"name\": \"leftthumb\"}, {\"id\": 2, \"name\": \"leftindex\"}, \n",
    "                       {\"id\": 3, \"name\": \"leftfour\"}, {\"id\": 4, \"name\": \"rightthumb\"},\n",
    "                       {\"id\": 5, \"name\": \"rightindex\"}, {\"id\": 6, \"name\": \"rightfour\"},\n",
    "                       {\"id\": 7, \"name\": \"emptyscanner\"}]\n",
    "    }\n",
    "\n",
    "    name_counter = {}\n",
    "\n",
    "    for folder in folders:\n",
    "        print('opening..', folder)\n",
    "        with open(os.path.join(folder, f'{t}.json'), 'r') as json_file:\n",
    "            annotations_data = json.load(json_file)\n",
    "\n",
    "        for i, image in enumerate(annotations_data[\"images\"]):\n",
    "            file_name = image[\"file_name\"]\n",
    "            src_image_path = os.path.join(folder, file_name)\n",
    "            print(i, 'processing for', file_name)\n",
    "            \n",
    "            # Renaming logic if filename exists\n",
    "            base_name, ext = os.path.splitext(file_name)\n",
    "            suffix = name_counter.get(base_name, 0)\n",
    "            if suffix:\n",
    "                new_file_name = f\"{base_name}_{chr(ord('a') + suffix)}{ext}\"\n",
    "            else:\n",
    "                new_file_name = file_name\n",
    "            \n",
    "            name_counter[base_name] = suffix + 1\n",
    "\n",
    "            # Updating the file_name in the JSON and copy to common directory\n",
    "            image[\"file_name\"] = new_file_name\n",
    "            dest_image_path = os.path.join(common_directory, new_file_name)\n",
    "            shutil.copyfile(src_image_path, dest_image_path)\n",
    "            image[\"id\"] += image_id_offset\n",
    "            final_json[\"images\"].append(image)\n",
    "\n",
    "        for annotation in annotations_data[\"annotations\"]:\n",
    "            # Round the segmentation values\n",
    "            annotation[\"segmentation\"] = [[round_to_nearest_half(value) for value in seg] for seg in annotation[\"segmentation\"]]\n",
    "            annotation[\"bbox\"] = [round_to_nearest_half(value) for value in annotation[\"bbox\"]]\n",
    "            annotation[\"image_id\"] += image_id_offset\n",
    "            annotation[\"id\"] += annotation_id_offset\n",
    "            final_json[\"annotations\"].append(annotation)\n",
    "\n",
    "        # Updating the image and annotation id offsets\n",
    "        image_id_offset += len(annotations_data[\"images\"])\n",
    "        annotation_id_offset += len(annotations_data[\"annotations\"])\n",
    "\n",
    "    # Write the merged JSON to the common directory\n",
    "    with open(os.path.join(common_directory, f'{t}.json'), 'w') as merged_file:\n",
    "        json.dump(final_json, merged_file)\n",
    "\n",
    "# List of folders to be merged\n",
    "t = 'train'\n",
    "folders = ['21Aug23_DDA', '21Aug23_DDA_B', '22Aug23_DDA', '22Aug23_DDA_b', '22Aug23_DDA_b']\n",
    "# Common directory for merged data|\n",
    "common_directory = f'final_23aug_{t}_processed_v2'\n",
    "merge_datasets(folders, common_directory, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25852ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "\n",
    "def round_to_nearest_half(number):\n",
    "    return round(number * 2) / 2\n",
    "\n",
    "def merge_datasets(folders, common_directory):\n",
    "    os.makedirs(common_directory, exist_ok=True)\n",
    "    image_id_offset = 0\n",
    "    annotation_id_offset = 0\n",
    "\n",
    "    final_json = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [{\"id\": 1, \"name\": \"lefthand\"}, {\"id\": 2, \"name\": \"righthand\"}]\n",
    "    }\n",
    "\n",
    "    name_counter = {}\n",
    "\n",
    "    for folder in folders:\n",
    "        with open(os.path.join(folder, 'annotations.json'), 'r') as json_file:\n",
    "            annotations_data = json.load(json_file)\n",
    "\n",
    "        for image in annotations_data[\"images\"]:\n",
    "            file_name = image[\"file_name\"]\n",
    "            src_image_path = os.path.join(folder, file_name)\n",
    "            \n",
    "            # Renaming logic if filename exists\n",
    "            base_name, ext = os.path.splitext(file_name)\n",
    "            suffix = name_counter.get(base_name, 0)\n",
    "            if suffix:\n",
    "                new_file_name = f\"{base_name}_{chr(ord('a') + suffix)}{ext}\"\n",
    "            else:\n",
    "                new_file_name = file_name\n",
    "            \n",
    "            name_counter[base_name] = suffix + 1\n",
    "\n",
    "            # Updating the file_name in the JSON and copy to common directory\n",
    "            image[\"file_name\"] = new_file_name\n",
    "            dest_image_path = os.path.join(common_directory, new_file_name)\n",
    "            shutil.copyfile(src_image_path, dest_image_path)\n",
    "            image[\"id\"] += image_id_offset\n",
    "            final_json[\"images\"].append(image)\n",
    "\n",
    "        for annotation in annotations_data[\"annotations\"]:\n",
    "            # Round the segmentation and bbox values\n",
    "            annotation[\"segmentation\"] = [[round_to_nearest_half(value) for value in seg] for seg in annotation[\"segmentation\"]]\n",
    "            annotation[\"bbox\"] = [round_to_nearest_half(value) for value in annotation[\"bbox\"]]\n",
    "            annotation[\"image_id\"] += image_id_offset\n",
    "            annotation[\"id\"] += annotation_id_offset\n",
    "            final_json[\"annotations\"].append(annotation)\n",
    "\n",
    "        # Updating the image and annotation id offsets\n",
    "        image_id_offset += len(annotations_data[\"images\"])\n",
    "        annotation_id_offset += len(annotations_data[\"annotations\"])\n",
    "\n",
    "    # Write the merged JSON to the common directory\n",
    "    with open(os.path.join(common_directory, 'merged_annotations.json'), 'w') as merged_file:\n",
    "        json.dump(final_json, merged_file, indent=4)\n",
    "\n",
    "# List of folders to be merged\n",
    "folders = ['01', '02']\n",
    "# Common directory for merged data\n",
    "common_directory = '03'\n",
    "merge_datasets(folders, common_directory)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702faf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
